{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git -q\n",
        "! pip install gradio -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OQQ9Bk-YCGt",
        "outputId": "5f15cf78-f735-4a37-f369-c73fa60453b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "usage: whisper\n",
        "       [-h]\n",
        "\n",
        "1.  \n",
        "\n",
        "\n",
        "       [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}]\n",
        "       [--model_dir MODEL_DIR]\n",
        "       [--device DEVICE]\n",
        "       [--output_dir OUTPUT_DIR]\n",
        "       [--output_format {txt,vtt,srt,tsv,json,all}]\n",
        "       [--verbose VERBOSE]\n",
        "       [--task {transcribe,translate}]\n",
        "       [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
        "       [--temperature TEMPERATURE]\n",
        "       [--best_of BEST_OF]\n",
        "       [--beam_size BEAM_SIZE]\n",
        "       [--patience PATIENCE]\n",
        "       [--length_penalty LENGTH_PENALTY]\n",
        "       [--suppress_tokens SUPPRESS_TOKENS]\n",
        "       [--initial_prompt INITIAL_PROMPT]\n",
        "       [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
        "       [--fp16 FP16]\n",
        "       [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
        "       [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
        "       [--logprob_threshold LOGPROB_THRESHOLD]\n",
        "       [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
        "       [--word_timestamps WORD_TIMESTAMPS]\n",
        "       [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
        "       [--append_punctuations APPEND_PUNCTUATIONS]\n",
        "       [--highlight_words HIGHLIGHT_WORDS]\n",
        "       [--max_line_width MAX_LINE_WIDTH]\n",
        "       [--max_line_count MAX_LINE_COUNT]\n",
        "       [--threads THREADS]\n",
        "       audio\n",
        "       [audio ...]"
      ],
      "metadata": {
        "id": "NKiSAHdTcIAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2fZRrD-YE0p",
        "outputId": "4efea3b1-9c7f-46be-8a3c-04a2897fc117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:24<00:00, 127MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text\n"
      ],
      "metadata": {
        "id": "vHG56SoVYZZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "xgNyv744Yzj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gr.Interface(\n",
        "    title = 'OpenAI Whisper',\n",
        "    fn=transcribe,\n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        \"textbox\"\n",
        "    ],\n",
        "    live=True).launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "JeIO041lY1j4",
        "outputId": "d4aec7d7-5fe2-4efe-99d2-439f3f455cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f803a3badb57>:5: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
            "<ipython-input-9-f803a3badb57>:5: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://1b25e2e7388fcaded2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1b25e2e7388fcaded2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# offline transcription"
      ],
      "metadata": {
        "id": "5NQp3s3iad_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose your file path and target language\n",
        "fileName = \"sample.m4a\"\n",
        "lang = \"en\""
      ],
      "metadata": {
        "id": "ccDcGxqnaZB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio\n",
        "audio = whisper.load_audio(f\"content/{fileName}\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "options = whisper.DecodingOptions(language=lang, without_timestamps=True)\n",
        "result = whisper.decode(model, mel, options)\n",
        "print(result.text)\n",
        "\n",
        "# Write into a text file\n",
        "with open(f\"download/{fileName}.txt\", \"w\") as f:\n",
        "  f.write(f\"▼ Transcription of {fileName}\\n\")\n",
        "  f.write(result.text)"
      ],
      "metadata": {
        "id": "D3Eea_cVaRlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import whisper\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "audio = \"audio.mp3\"\n",
        "result = model.transcribe(audio)\n",
        "output_directory = \"./\"\n",
        "\n",
        "\n",
        "# Save as a TXT file without any line breaks\n",
        "with open(\"transcription.txt\", \"w\", encoding=\"utf-8\") as txt:\n",
        "    txt.write(result[\"text\"])\n",
        "\n",
        "\n",
        "# Save as a TXT file with hard line breaks\n",
        "txt_writer = get_writer(\"txt\", output_directory)\n",
        "txt_writer(result, audio)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jFEaVuTmeBqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}